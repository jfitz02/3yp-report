{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for keras-ocr\n",
    "from keras_ocr.detection import Detector\n",
    "from keras_ocr.pipeline import Pipeline\n",
    "from keras_ocr.recognition import Recognizer\n",
    "from keras_ocr.tools import read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for getting the image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get camera\n",
    "cap = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\jfitz\\.keras-ocr\\craft_mlt_25k.h5\n",
      "Looking for C:\\Users\\jfitz\\.keras-ocr\\crnn_kurapan.h5\n",
      "1/1 [==============================] - 15s 15s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "[('5', array([[809.8594 ,  88.25391],\n",
      "       [837.11426,  88.25391],\n",
      "       [837.11426, 124.59375],\n",
      "       [809.8594 , 124.59375]], dtype=float32)), ('mph', array([[796.88086, 129.78516],\n",
      "       [850.0928 , 129.78516],\n",
      "       [850.0928 , 146.65723],\n",
      "       [796.88086, 146.65723]], dtype=float32)), ('one', array([[768.3281 , 171.3164 ],\n",
      "       [813.7529 , 171.3164 ],\n",
      "       [813.7529 , 192.08203],\n",
      "       [768.3281 , 192.08203]], dtype=float32)), ('way', array([[831.92285, 172.61426],\n",
      "       [877.34766, 172.61426],\n",
      "       [877.34766, 192.08203],\n",
      "       [831.92285, 192.08203]], dtype=float32)), ('sample', array([[ 24.719616, 192.60399 ],\n",
      "       [210.6905  , 185.09001 ],\n",
      "       [213.03369 , 243.08403 ],\n",
      "       [ 27.062807, 250.598   ]], dtype=float32)), ('text', array([[224.52832, 190.78418],\n",
      "       [332.25   , 190.78418],\n",
      "       [332.25   , 240.10254],\n",
      "       [224.52832, 240.10254]], dtype=float32)), ('photo', array([[653.79065, 216.     ],\n",
      "       [692.25757, 208.67297],\n",
      "       [694.69995, 221.49527],\n",
      "       [656.23303, 228.82231]], dtype=float32)), ('another', array([[ 27.418293, 284.3269  ],\n",
      "       [150.83856 , 286.5709  ],\n",
      "       [150.41737 , 309.73578 ],\n",
      "       [ 26.997108, 307.4918  ]], dtype=float32)), ('sample', array([[152.45352, 287.84705],\n",
      "       [256.47836, 282.8935 ],\n",
      "       [257.9524 , 313.8481 ],\n",
      "       [153.92754, 318.8017 ]], dtype=float32)), ('text', array([[262.16602, 284.2295 ],\n",
      "       [332.25   , 284.2295 ],\n",
      "       [332.25   , 307.59082],\n",
      "       [262.16602, 307.59082]], dtype=float32)), ('colored', array([[ 28.552734, 358.20703 ],\n",
      "       [166.125   , 358.20703 ],\n",
      "       [166.125   , 385.4619  ],\n",
      "       [ 28.552734, 385.4619  ]], dtype=float32)), ('sample', array([[179.10352, 362.1006 ],\n",
      "       [298.50586, 362.1006 ],\n",
      "       [298.50586, 385.4619 ],\n",
      "       [179.10352, 385.4619 ]], dtype=float32)), ('text', array([[311.48438, 362.1006 ],\n",
      "       [385.4619 , 362.1006 ],\n",
      "       [385.4619 , 385.4619 ],\n",
      "       [311.48438, 385.4619 ]], dtype=float32)), ('the', array([[835.8164 , 416.61035],\n",
      "       [865.667  , 416.61035],\n",
      "       [865.667  , 434.78027],\n",
      "       [835.8164 , 434.78027]], dtype=float32)), ('share', array([[782.6045 , 417.9082 ],\n",
      "       [833.2207 , 417.9082 ],\n",
      "       [833.2207 , 434.78027],\n",
      "       [782.6045 , 434.78027]], dtype=float32)), ('road', array([[804.66797, 437.37598],\n",
      "       [846.1992 , 437.37598],\n",
      "       [846.1992 , 455.5459 ],\n",
      "       [804.66797, 455.5459 ]], dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Load the detector\n",
    "detector = Detector()\n",
    "\n",
    "# Load the recognizer\n",
    "recognizer = Recognizer()\n",
    "\n",
    "# Load the pipeline\n",
    "pipeline = Pipeline(detector=detector, recognizer=recognizer)\n",
    "\n",
    "# get image from test.png\n",
    "image = read('test.png')\n",
    "\n",
    "# get predictions\n",
    "predictions = pipeline.recognize(images=[image])[0]\n",
    "\n",
    "# print predictions\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97999f904c5bcf44446ad9fa0f3977d04350a64ad2233c4cf3d5a942bd2f4055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
